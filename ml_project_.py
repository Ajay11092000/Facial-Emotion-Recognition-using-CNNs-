# -*- coding: utf-8 -*-
"""Advanced ML Project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BjbZ-y_Jq5W88inG9QX1-bBXHa9zdeKz
"""

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/My Drive/Advance ML/datasets.zip" -d "/content/dataset"

import os
print(os.listdir("/content/dataset"))

import cv2
import matplotlib.pyplot as plt

image_path = "/content/dataset/train/sad/Training_83450818.jpg"
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# Show the image
plt.imshow(image, cmap="gray")
plt.axis("off")
plt.show()

# Import Libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""Preprocessing

"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = "/content/dataset/train"
test_dir = "/content/dataset/test"

# Emotion Labels
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

# Data Augmentation
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    zoom_range=0.1,
    horizontal_flip=True,
    shear_range=0.1,
    validation_split=0.2  # Splitting for validation
)

# Load Training & Validation Data
train_data = datagen.flow_from_directory(
    train_dir, target_size=(48, 48), color_mode="grayscale",
    batch_size=64, class_mode='categorical', subset="training"
)

val_data = datagen.flow_from_directory(
    train_dir, target_size=(48, 48), color_mode="grayscale",
    batch_size=64, class_mode='categorical', subset="validation"
)

# Load Test Data
test_data = ImageDataGenerator(rescale=1./255).flow_from_directory(
    test_dir, target_size=(48, 48), color_mode="grayscale",
    batch_size=64, class_mode='categorical'
)

print("âœ… Dataset Preprocessing Done! Ready for Model Training.")

import cv2
import matplotlib.pyplot as plt
import numpy as np

# Load an original image (Before Preprocessing)
image_path = "/content/dataset/train/happy/Training_926400.jpg"  # Update with an actual image path
original_image = cv2.imread(image_path)  # Load in BGR format

# Convert to Grayscale (Preprocessing Step)
preprocessed_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# Resize to 48x48 (Preprocessing Step)
preprocessed_image = cv2.resize(preprocessed_image, (48, 48))

# Normalize (Preprocessing Step)
preprocessed_image = preprocessed_image / 255.0

# Display Images
fig, ax = plt.subplots(1, 2, figsize=(10, 5))

# Original Image
ax[0].imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct color display
ax[0].set_title("Before Preprocessing")
ax[0].axis("off")

# Preprocessed Image
ax[1].imshow(preprocessed_image, cmap="gray")
ax[1].set_title("After Preprocessing (48x48 Grayscale & Normalized)")
ax[1].axis("off")

plt.show()

from tensorflow.keras.layers import Conv2D, LeakyReLU

Conv2D(64, (3, 3), padding='same'),
LeakyReLU(alpha=0.1)  # Ensure alpha is set properly

""" Implement CNN Models


ðŸ”¹ Implement  VGG Model
"""

# Import required libraries
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import Adam

# Define Custom VGG Model
def create_custom_vgg():
    model = Sequential([
        # First Convolutional Block
        Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1)),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        # Second Convolutional Block
        Conv2D(128, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        # Third Convolutional Block
        Conv2D(256, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Conv2D(256, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        # Fully Connected Layers
        Flatten(),
        Dense(512),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),

        Dense(256),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),

        Dense(128),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),

        Dense(7, activation='softmax')  # Output Layer (7 Emotion Classes)
    ])

    # Compile Model
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])

    return model

# Create and print the model architecture
custom_vgg_model = create_custom_vgg()
print("\nðŸ”¹ Custom VGG Model Architecture:")
custom_vgg_model.summary()

""" IMPLEMENT VGG16 MODEL"""

def create_vgg16():
    model = Sequential([
        Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1)),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Conv2D(64, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        Conv2D(128, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Conv2D(128, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        Flatten(),
        Dense(512),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),
        Dense(256),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),
        Dense(7, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])
    return model

vgg16_model = create_vgg16()

print("\nðŸ”¹ VGG16 Model Architecture:")
vgg16_model.summary()

"""IIMPLEMENT VGG19 MODEL"""

def create_vgg19():
    model = Sequential([
        Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1)),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Conv2D(64, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        Conv2D(128, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        Conv2D(128, (3, 3), padding='same'),
        BatchNormalization(),
        LeakyReLU(alpha=0.01),
        MaxPooling2D((2, 2)),

        Flatten(),
        Dense(512),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),
        Dense(256),
        LeakyReLU(alpha=0.01),
        Dropout(0.25),
        Dense(7, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])
    return model

vgg19_model = create_vgg19()

print("\nðŸ”¹ VGG19 Model Architecture:")
vgg19_model.summary()

"""IMPLEMENT INCEPTION MODEL"""

# Ensure necessary imports
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, AveragePooling2D
from tensorflow.keras.optimizers import Adam

def create_inception():
    input_layer = Input(shape=(48, 48, 1))

    x = Conv2D(32, (3,3), padding='same')(input_layer)
    x = LeakyReLU(alpha=0.01)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2,2))(x)

    x = Conv2D(64, (3,3), padding='same')(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2,2))(x)

    x = Conv2D(128, (3,3), padding='same')(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = BatchNormalization()(x)
    x = AveragePooling2D((2,2))(x)

    x = Flatten()(x)
    x = Dense(256)(x)
    x = LeakyReLU(alpha=0.01)(x)
    x = Dropout(0.25)(x)

    output_layer = Dense(7, activation='softmax')(x)

    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])

    return model

# Create the Inception model
inception_model = create_inception()

# Print the model architecture
print("\nðŸ”¹ Inception Model Architecture:")
inception_model.summary()

"""Train All Models


We will now train VGG, VGG16, VGG19, and Inception for 30 epochs
"""

# Set the number of epochs
epochs = 30

# Train all models
history_vgg = custom_vgg_model.fit(train_data, validation_data=val_data, epochs=epochs)
history_vgg16 = vgg16_model.fit(train_data, validation_data=val_data, epochs=epochs)
history_vgg19 = vgg19_model.fit(train_data, validation_data=val_data, epochs=epochs)
history_inception = inception_model.fit(train_data, validation_data=val_data, epochs=epochs)

""" Evaluate & Compare Models


After training, we evaluate accuracy, loss, and inference speed.
"""

import time
import pandas as pd  # Import pandas for DataFrame handling

# Function to measure inference time
def measure_inference_time(model, test_data, num_samples=100):
    test_iter = iter(test_data)
    batch_images, _ = next(test_iter)

    num_samples = min(num_samples, batch_images.shape[0])
    images = batch_images[:num_samples]

    start_time = time.time()
    _ = model.predict(images, verbose=0)
    end_time = time.time()

    avg_time = (end_time - start_time) / num_samples
    return avg_time

# Evaluate all models on test data
models = [custom_vgg_model, vgg16_model, vgg19_model, inception_model]
model_names = ["Custom VGG", "VGG16", "VGG19", "Inception"]
results = {}

for model, name in zip(models, model_names):
    loss, acc = model.evaluate(val_data, verbose=1)
    inference_time = measure_inference_time(model, val_data)

    results[name] = {"Accuracy": acc, "Loss": loss, "Inference Time (sec/image)": inference_time}
    print(f"âœ… {name} Accuracy: {acc:.4f} | Loss: {loss:.4f} | Inference Time: {inference_time:.6f} sec/image")

# Convert results to a table
df_results = pd.DataFrame(results).T
print("\nðŸ“Š Model Comparison:\n", df_results)

"""Generate Comparison Graphs


We now visualize accuracy, loss, and inference time.
"""

# Plot accuracy comparison
plt.figure(figsize=(8,5))
plt.bar(df_results.index, df_results["Accuracy"], color=['blue', 'green', 'red', 'purple'])
plt.ylabel("Test Accuracy")
plt.title("Model Accuracy Comparison")
plt.show()

# Plot loss comparison
plt.figure(figsize=(8,5))
plt.bar(df_results.index, df_results["Loss"], color=['blue', 'green', 'red', 'purple'])
plt.ylabel("Test Loss")
plt.title("Model Loss Comparison")
plt.show()

# Plot inference time comparison
plt.figure(figsize=(8,5))
plt.bar(df_results.index, df_results["Inference Time (sec/image)"], color=['blue', 'green', 'red', 'purple'])
plt.ylabel("Inference Time (seconds per image)")
plt.title("Model Inference Speed Comparison")
plt.show()

"""Ensemble Learning for Better Accuracy


Instead of using just one model, we combine VGG, VGG16, VGG19, and Inception for ensemble learning.
"""

import numpy as np

# Function to get true labels from a batch
def get_true_labels(data):
    batch_images, batch_labels = next(iter(data))
    true_labels = np.argmax(batch_labels, axis=1)
    return batch_images, true_labels

# Ensemble prediction using softmax confidence weighting
def ensemble_predict(models, weights, data):
    batch_images, true_labels = get_true_labels(data)

    predictions = np.array([model.predict(batch_images) for model in models])
    weighted_predictions = np.average(predictions, axis=0, weights=weights)

    ensemble_pred_labels = np.argmax(weighted_predictions, axis=1)
    accuracy = np.mean(ensemble_pred_labels == true_labels)

    return accuracy

# Assign weights based on individual model performance
weights = [0.25, 0.25, 0.25, 0.25]
ensemble_accuracy = ensemble_predict([custom_vgg_model, vgg16_model, vgg19_model, inception_model], weights, val_data)

print(f"\nðŸš€ Improved Ensemble Accuracy: {ensemble_accuracy:.4f}")

""" Save Models for Future Use"""

custom_vgg_model.save("/content/custom_vgg_model.keras", save_format="keras")
vgg16_model.save("/content/vgg16_model.keras", save_format="keras")
vgg19_model.save("/content/vgg19_model.keras", save_format="keras")
inception_model.save("/content/inception_model.keras", save_format="keras")

print("âœ… All models saved successfully!")

""" Test the Models on a New Image"""

import cv2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from google.colab import files

# Upload an image
uploaded = files.upload()

# Get uploaded file path
image_path = list(uploaded.keys())[0]

# Load and preprocess the image
image = load_img(image_path, color_mode="grayscale", target_size=(48, 48))
image = img_to_array(image) / 255.0
image = np.expand_dims(image, axis=0)

# Predict using all models
vgg_pred = custom_vgg_model.predict(image, verbose=0)
vgg16_pred = vgg16_model.predict(image, verbose=0)
vgg19_pred = vgg19_model.predict(image, verbose=0)
inception_pred = inception_model.predict(image, verbose=0)

# Ensemble Prediction
ensemble_pred = (vgg_pred * 0.25) + (vgg16_pred * 0.25) + (vgg19_pred * 0.25) + (inception_pred * 0.25)

# Emotion labels
emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']

# Get final predictions
vgg_emotion = emotion_labels[np.argmax(vgg_pred)]
vgg16_emotion = emotion_labels[np.argmax(vgg16_pred)]
vgg19_emotion = emotion_labels[np.argmax(vgg19_pred)]
inception_emotion = emotion_labels[np.argmax(inception_pred)]
ensemble_emotion = emotion_labels[np.argmax(ensemble_pred)]

# Print Predictions
print(f"âœ… Custom VGG Prediction: {vgg_emotion}")
print(f"âœ… VGG16 Prediction: {vgg16_emotion}")
print(f"âœ… VGG19 Prediction: {vgg19_emotion}")
print(f"âœ… Inception Prediction: {inception_emotion}")
print(f"ðŸš€ Final Ensemble Prediction: {ensemble_emotion}")

# Display the image
image_display = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
plt.imshow(image_display, cmap="gray")
plt.axis("off")
plt.title(f"VGG: {vgg_emotion} | VGG16: {vgg16_emotion} | VGG19: {vgg19_emotion} | Inception: {inception_emotion} | Ensemble: {ensemble_emotion}")
plt.show()